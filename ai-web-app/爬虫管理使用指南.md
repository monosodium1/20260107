# 爬虫管理模块使用指南

## 一、模块概述

爬虫管理模块是一个**通用爬虫引擎**，支持：
- ✅ 配置化管理爬虫源（百度、Google、自定义网站等）
- ✅ 创建和执行爬虫任务
- ✅ 实时查看爬取进度和结果
- ✅ 支持GET/POST请求
- ✅ 自定义请求头和请求体
- ✅ 灵活的数据提取配置（CSS选择器）

---

## 二、快速开始示例

### 示例1：使用百度搜索爬虫

#### 步骤1：添加百度搜索爬虫源

1. 访问 [http://localhost:5000/crawler](http://localhost:5000/crawler)
2. 点击"新增源"按钮
3. 填写以下信息：

```
源名称：百度搜索
源类型：百度搜索
描述：百度搜索引擎爬虫
URL模板：https://www.baidu.com/s?wd={keyword}&pn={page}&ie=utf-8
请求方法：GET
状态：活跃
```

**数据提取配置**：
```
数据选择器（JSON格式）：
{
  "type": "css",
  "selector": "div.result"
}

标题选择器：h3.t a
URL选择器：h3.t a
摘要选择器：div.c-abstract, div.c-span-last
图片选择器：（留空）
```

4. 点击"保存"

#### 步骤2：创建爬虫任务

1. 点击"新增任务"按钮
2. 填写以下信息：

```
任务名称：搜索林俊杰
爬虫源：百度搜索
搜索关键词：林俊杰
起始页：1
总页数：2
每页数量：10
```

3. 点击"创建任务"

#### 步骤3：运行任务

1. 在任务列表中找到刚创建的任务
2. 点击绿色的"播放"按钮（▶）
3. 等待任务完成（状态变为"已完成"）

#### 步骤4：查看采集数据

1. 滚动到页面下方的"采集数据"区域
2. 查看爬取到的标题、URL、摘要等信息
3. 点击标题可以跳转到原始网页

---

### 示例2：创建自定义爬虫（以某新闻网站为例）

假设我们要爬取一个新闻网站的搜索结果：

#### 步骤1：分析目标网站

目标网站：`https://news.example.com/search`

搜索URL格式：
```
https://news.example.com/search?q=关键词&page=1
```

HTML结构（示例）：
```html
<div class="news-item">
  <h3 class="title">
    <a href="https://news.example.com/article/123">新闻标题</a>
  </h3>
  <p class="summary">新闻摘要内容...</p>
  <img src="https://news.example.com/img/cover.jpg" class="cover">
</div>
```

#### 步骤2：添加自定义爬虫源

1. 点击"新增源"按钮
2. 填写以下信息：

```
源名称：示例新闻网站
源类型：自定义爬虫
描述：示例新闻网站搜索爬虫
URL模板：https://news.example.com/search?q={keyword}&page={page}
请求方法：GET
状态：活跃
```

**请求头（可选）**：
```json
{
  "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
  "Referer": "https://news.example.com"
}
```

**数据提取配置**：
```
数据选择器（JSON格式）：
{
  "type": "css",
  "selector": "div.news-item"
}

标题选择器：h3.title a
URL选择器：h3.title a
摘要选择器：p.summary
图片选择器：img.cover
```

3. 点击"保存"

#### 步骤3：创建并运行任务

1. 点击"新增任务"
2. 填写信息：
   - 任务名称：搜索科技新闻
   - 爬虫源：示例新闻网站
   - 搜索关键词：人工智能
   - 起始页：1
   - 总页数：3
   - 每页数量：10
3. 点击"创建任务"
4. 运行任务并查看结果

---

### 示例3：POST请求爬虫

某些网站使用POST方法提交搜索请求：

#### 步骤1：添加POST爬虫源

```
源名称：某API搜索
源类型：自定义爬虫
URL模板：https://api.example.com/search
请求方法：POST
状态：活跃
```

**请求体模板（JSON格式）**：
```json
{
  "keyword": "{keyword}",
  "page": {page},
  "size": 10
}
```

**数据提取配置**：
```
数据选择器：
{
  "type": "css",
  "selector": "div.result-item"
}

标题选择器：h4.title
URL选择器：a.link
摘要选择器：p.description
图片选择器：img.thumbnail
```

---

## 三、配置详解

### 3.1 URL模板变量

支持的变量：
- `{keyword}` - 搜索关键词
- `{page}` - 页码
- `{limit}` - 每页数量

**示例**：
```
https://example.com/search?q={keyword}&page={page}&limit={limit}
```

### 3.2 请求头配置

在"请求头"字段中输入JSON格式的请求头：

```json
{
  "User-Agent": "自定义User-Agent",
  "Authorization": "Bearer token123",
  "Referer": "https://example.com"
}
```

### 3.3 数据提取配置

#### 方式1：使用数据选择器（推荐）

```json
{
  "type": "css",
  "selector": "div.result"
}
```

- `type`: 选择器类型，支持 `css` 或 `xpath`
- `selector`: 选择器表达式

#### 方式2：使用单独的选择器

如果不使用数据选择器，可以直接配置：
- 标题选择器：`h3.title a`
- URL选择器：`a.link`
- 摘要选择器：`p.summary`
- 图片选择器：`img.cover`

### 3.4 CSS选择器基础

**常用选择器**：
- `.class` - 类选择器：`div.result`
- `#id` - ID选择器：`div#content`
- `tag` - 标签选择器：`h3`
- `tag.class` - 标签+类：`h3.title`
- `parent > child` - 子选择器：`div.result > h3`
- `parent space child` - 后代选择器：`div.result a`

**示例**：
```
标题选择器：h3.title a
URL选择器：h3.title a
摘要选择器：div.summary
图片选择器：img.cover
```

---

## 四、常见问题

### Q1：爬取不到数据怎么办？

**解决方法**：
1. 检查URL模板是否正确
2. 检查数据选择器是否匹配HTML结构
3. 查看浏览器开发者工具，确认HTML结构
4. 检查是否需要添加请求头（如User-Agent、Referer等）
5. 检查网站是否有反爬机制（如需要登录、验证码等）

### Q2：如何查看网站的HTML结构？

**步骤**：
1. 在浏览器中打开目标网站
2. 右键点击页面，选择"检查"或按F12
3. 使用元素选择工具（左上角箭头图标）
4. 点击要提取的元素
5. 在Elements面板中查看HTML结构
6. 根据HTML结构编写CSS选择器

### Q3：任务一直显示"运行中"怎么办？

**解决方法**：
1. 检查网站是否可以正常访问
2. 检查URL模板是否正确
3. 查看服务器日志，确认是否有错误
4. 尝试停止任务后重新运行

### Q4：如何处理分页？

**方法1：URL参数分页**
```
URL模板：https://example.com/search?q={keyword}&page={page}
```

**方法2：URL路径分页**
```
URL模板：https://example.com/search/{keyword}/page/{page}
```

**方法3：POST请求体分页**
```json
{
  "keyword": "{keyword}",
  "page": {page}
}
```

### Q5：如何处理需要登录的网站？

**方法1：在请求头中添加Cookie**
```json
{
  "Cookie": "session_id=xxx; token=yyy"
}
```

**方法2：使用Authorization头**
```json
{
  "Authorization": "Bearer token123"
}
```

---

## 五、高级技巧

### 5.1 使用XPath选择器

```json
{
  "type": "xpath",
  "selector": "//div[@class='result']"
}
```

### 5.2 处理动态加载的内容

对于JavaScript动态加载的内容，可能需要：
1. 使用Selenium等工具（需要额外开发）
2. 分析API接口，直接调用API
3. 使用headless浏览器

### 5.3 添加延迟和重试

在代码中可以添加：
```python
import time

time.sleep(2)  # 延迟2秒
```

### 5.4 处理编码问题

如果遇到中文乱码：
```python
response.encoding = 'utf-8'
```

---

## 六、最佳实践

1. **遵守robots.txt**：尊重网站的爬虫协议
2. **控制爬取频率**：避免给目标网站造成过大压力
3. **设置合理的User-Agent**：模拟真实浏览器访问
4. **添加错误处理**：处理网络异常、超时等情况
5. **定期更新配置**：网站结构可能变化，需要及时更新选择器
6. **使用代理IP**：避免IP被封（需要额外配置）

---

## 七、完整工作流程

```
1. 访问爬虫管理页面
   ↓
2. 分析目标网站（查看HTML结构）
   ↓
3. 添加爬虫源（配置URL、选择器等）
   ↓
4. 创建爬虫任务（设置关键词、页数等）
   ↓
5. 运行任务（点击播放按钮）
   ↓
6. 查看采集数据（在页面下方查看结果）
   ↓
7. 保存数据（在采集管理模块保存）
```

---

## 八、示例配置库

### 百度搜索
```
URL: https://www.baidu.com/s?wd={keyword}&pn={page}&ie=utf-8
数据选择器：{"type": "css", "selector": "div.result"}
标题选择器：h3.t a
URL选择器：h3.t a
摘要选择器：div.c-abstract, div.c-span-last
```

### Google搜索
```
URL: https://www.google.com/search?q={keyword}&start={page}
数据选择器：{"type": "css", "selector": "div.g"}
标题选择器：h3
URL选择器：a
摘要选择器：div.VwiC3b
```

### 知乎搜索
```
URL: https://www.zhihu.com/search?q={keyword}&type=content
数据选择器：{"type": "css", "selector": "div.List-item"}
标题选择器：a.ContentItem-title
URL选择器：a.ContentItem-title
摘要选择器：span.RichContent-innerText
```

---

## 九、技术支持

如遇到问题，请检查：
1. 服务器日志：`e:\work\20260107\ai-web-app\logs\`
2. 数据库：确认爬虫源和任务是否正确保存
3. 网络连接：确认可以访问目标网站

---

## 十、下一步

完成数据采集后，可以：
1. 在**采集管理**模块中查看和保存数据
2. 在**数据管理**模块中管理和搜索已保存的数据
3. 使用**AI深度采集**功能进行智能分析
